{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bu-UZ99rILw"
   },
   "source": [
    "# **NSFW Classifier - A Baseline Model**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### **Purpose**\n",
    "\n",
    "The aim of this notebook is to showcase a **baseline model** for NSFW classification by **transfer learning**. A **custom dataset** containing approximately 2500 JPEG images of each class (NSFW/SFW) was used to fine-tune a **pre-trained ResNet50** ConvNet model.\n",
    "\n",
    "### **Framework**\n",
    "The model was trained in **Fastai**, which is a high-level API on top of **PyTorch**. While this framework has, in my opinion, many drawbacks, it's a great one for **fast prototyping**, reducing both training time and lines of code. However, for production level models, my choice would be Tensorflow + Keras. \n",
    "\n",
    "### **Methodology**\n",
    "The methodology used for creating the dataset is outlined in a separate section below.\n",
    "\n",
    "The Fully Connected (FC) layer of the pre-trained ResNet50 model was removed and *two* new FC layers were added to the remaining convolutional base in its place. **Why two?** This is one of the particularities of Fastai. Simply, their research team have found that adding one additional dense layer often gets better results. \n",
    "\n",
    "All of the above happens under the hood when instantiating a pre-trained model. This is one of the drawbacks I was hinting at above - often in Fastai, it can be difficult to figure out what is going on (even by reading the docs).\n",
    "\n",
    "The resulting model was trained on the NSFW dataset following an **80/20 train/validate split** for **5 epochs** using a **learning rate of 3-e3**, with Adam as the chosen optimizer and no additional frills other than **normalizing** the images using the statistics of the pretrained model. Again, most of this happens under the hood.\n",
    "\n",
    "### **Expected outcomes**\n",
    "ResNet50 was pre-trained on **Imagenet** - a dataset containing millions of images across thousands of different classes, including people, animals, landscapes, everyday scenes and objects, etc. This dataset can be thought of as quite similar to our custom NSFW dataset, as opposed to for example a dataset containing, say, microscope or x-ray images. \n",
    "\n",
    "ResNet50-based models have consistently achieved **SOTA results** across a variety of computer vision tasks since 2015, and it would seem reasonable to expect that even a baseline model trained for a few epochs could achieve an **accuracy in the range of 85-90%**.\n",
    "\n",
    "Due to ResNet50's complexity in terms of layer depth and number of parameters, combined with the small size of our custom dataset, we would also expect the model to start **overfitting** quite quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9eqQZEorgtT"
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "I decided to create a custom dataset using the following GitHub sources:\n",
    "\n",
    "-  **SFW images**: The **neutral.txt** file from [alex000kim/nsfw_data_scraper](https://github.com/alex000kim/nsfw_data_scraper/tree/master/scripts/source_urls)\n",
    "- **NSFW images**: All the NSFW links from [EBazarov/nsfw_data_source_urls](https://github.com/EBazarov/nsfw_data_source_urls)\n",
    "\n",
    "These sources are discussed in the Datasets comparison report.\n",
    "\n",
    "For the purpose of creating the dataset, I wrote 3 **bash scripts**, that can be found in the script folder in this same repo:\n",
    "\n",
    "1. `get_urls.bash`: crawls the links a txt file containing domain urls (for instance, a whole subreddit) and extracts image urls from them, saving them to a txt file.\n",
    "\n",
    "2. `get_url_sample.bash`: given a txt file containing image urls,\n",
    "creates a random sample of size n and outputs it as a new txt file.\n",
    "\n",
    "3. `get_images.bash`: given a txt file containing image urls, downloads them using wget. Files that already exist in the target directory are not downloaded again.\n",
    "\n",
    "The **first script** yielded ~35.000 direct links to SFW images, and ~85.000 to NSFW images.\n",
    "\n",
    "From these links, I randomly sampled **~2500 images from each category** by using the **second script**, and subsequently downloaded them with the **third script**.\n",
    "\n",
    "As some of the links were dead, and some of the images corrupted, I ended up with **2434 NSFW** and **2495 SFW** images, for a grand total of **4929** images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWIOUO864VMk"
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wso7bcImurkV"
   },
   "outputs": [],
   "source": [
    "# Setup Fastai Colab environment\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tQae-K8Su8mh"
   },
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.all import *\n",
    "import os\n",
    "\n",
    "# Some files got mildly corruped during upload to Google Drive.\n",
    "# This helps avoids some problems down the line\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Fv1wt-12vtb3",
    "outputId": "40204a5e-0163-45c8-f139-7f0a22061bd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NSFW', 'SFW']"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locate image folders\n",
    "os.listdir(\"../content/gdrive/My Drive/Datasets/Large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "060BAvMav5Pe",
    "outputId": "9cfa0d93-e2f4-4afd-dffd-9b11c6ed7ce3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('../content/gdrive/My Drive/Datasets/Large/NSFW'),Path('../content/gdrive/My Drive/Datasets/Large/SFW')]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Path object to image folders\n",
    "path=Path(\"../content/gdrive/My Drive/Datasets/Large\")\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Wz364vZFh7EN",
    "outputId": "59de75fa-ab19-4037-f043-14ec333a92e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total NSFW images: 2434\n",
      "total SFW images: 2495\n"
     ]
    }
   ],
   "source": [
    "print('total NSFW images:', len(os.listdir(os.path.join(path, \"NSFW\"))))\n",
    "print('total SFW images:', len(os.listdir(os.path.join(path, \"SFW\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6rj8krK_B2A"
   },
   "source": [
    "## Setting up the image dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "3z8Ch-rowWF8"
   },
   "outputs": [],
   "source": [
    "# Define input params for data block \n",
    "\n",
    "# This sets up a train/validate split of 80/20\n",
    "splitter=RandomSplitter(valid_pct=0.2, seed=seed) \n",
    "# ResNet50 requires an input size of (224, 224, 3)\n",
    "item_tfms = [Resize(224)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "yMcPXZCOw8Mk"
   },
   "outputs": [],
   "source": [
    "# Create blueprint for dataloader\n",
    "data_block = DataBlock(\n",
    "                  blocks=[ImageBlock, CategoryBlock],\n",
    "                  get_items=get_image_files,\n",
    "                  get_y=parent_label,\n",
    "                  splitter=splitter,\n",
    "                  item_tfms=item_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "OlOfIAYaw_jH"
   },
   "outputs": [],
   "source": [
    "# Create dataloader with batch size = 64 \n",
    "dls = data_block.dataloaders(path, bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_dlvoR-962J"
   },
   "source": [
    "## Taking a sneak-peak at the images\n",
    "\n",
    "I've not included the output of this cell, for obvious reasons.\n",
    "\n",
    "Of the 9 images displayed, 5 were labeled SFW, and 4 NSFW. All are correctly labeled, although one of the SFW images - a scantily clad female - is very close to being NSFW, depending on were one choses to draw the line.\n",
    "\n",
    "All but one of the images - a bowl of ramen - depict people, alone or in groups. One is a close up of a tattooed arm, and one is a collage of two different pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzGaPw9Txy-P"
   },
   "outputs": [],
   "source": [
    "# Run this cell at your own peril!\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Lafiwwa_S-t"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ercRgO61ySOs",
    "outputId": "249d320e-4011-49b3-f853-a8adfeb58ad1"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "function ClickConnect(){\n",
       "console.log(\"Working\");\n",
       "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
       "}setInterval(ClickConnect,60000)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prevents getting disconnected, use only when training in Colab\n",
    "%%javascript\n",
    "function ClickConnect(){\n",
    "console.log(\"Working\");\n",
    "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
    "}setInterval(ClickConnect,60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "rGL6WlYyyv1S",
    "outputId": "9ced4147-aada-42ab-a4d6-26326d09b07f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.489267</td>\n",
       "      <td>0.411146</td>\n",
       "      <td>0.890355</td>\n",
       "      <td>05:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.249647</td>\n",
       "      <td>0.287160</td>\n",
       "      <td>0.923858</td>\n",
       "      <td>04:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.167035</td>\n",
       "      <td>0.299071</td>\n",
       "      <td>0.909645</td>\n",
       "      <td>04:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.116006</td>\n",
       "      <td>0.272392</td>\n",
       "      <td>0.918782</td>\n",
       "      <td>05:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.061755</td>\n",
       "      <td>0.265079</td>\n",
       "      <td>0.930964</td>\n",
       "      <td>05:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>0.292940</td>\n",
       "      <td>0.924873</td>\n",
       "      <td>05:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate a pre-trained model by substituting the top FC layer with two new ones. (Happens under the hood)\n",
    "learn = cnn_learner(dls, resnet50, metrics=accuracy)\n",
    "# Train the new FC layers for 5 epochs\n",
    "learn.fine_tune(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajUrxGe3E7lm"
   },
   "source": [
    "## Training results\n",
    "\n",
    "Fastai has no convenient way of plotting the training and validation loss curves (it used to have one, but it's no longer working for some reason), but from the table above we get a pretty clear picture of what is going on:\n",
    "\n",
    "- The **training loss** converges rather smoothly and quite fast reaching 0.03 at the end.\n",
    "- After an intial downward jump, the **validation loss** stalls in the very beginning of training and seems to start diverging at the end of the last epoch, although there is not enough data to really tell. \n",
    "- The model behaves the way we would expect it to: showing signs of **overfitting** already early on.\n",
    "- The final **accuracy** is ~92.5%, which is promising at this stage, even though we wouldn't expect it to generalize well to unseen data. \n",
    "- We also note that training on a dataset containing 5000 images takes around **5 min/epoch**.\n",
    "\n",
    "\n",
    "Next, let's take a look at the **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "cw6lrfp0zhpZ",
    "outputId": "a60495d7-bba3-4748-c6c8-2e90a1dccd56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKOar1D9JZRG"
   },
   "source": [
    "## Confusion matrix\n",
    "\n",
    "The main takeaway here is that **NSFW images were incorrectly classified about twice as often as SFW images**, which is not too great if our primary aim is to protect innocent people's eyeballs and sensibilities from unsavoury content.\n",
    "\n",
    "If this were a commercial NSFW filter, we would prefer to **err on the side of caution** - flagging as many of the NSFW images as possible at the expense of catching a few of the innocent ones too. \n",
    "\n",
    "One way to achieve this could simply be to **change the threshold** of the inference score so that we cast a wider net, increasing recall for the NSFW category while reducing overall precision. Luckily, there are many other ways in which we can improve our model before having to consider this option.\n",
    "\n",
    "Next, we're going to take a look at those cases where the model was most ***confidently incorrect***, that is, the misclassified images with the highest losses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXfKikTVN283"
   },
   "source": [
    "## Misclassified images\n",
    "\n",
    "Below are 9 of the **most badly misclassified** images. Again, I'm not displaying them for obvious reasons. In all cases, the model assigned a probability of 1 to the images - meaning it was 100% sure they belonged to the incorrect class. Ouch!\n",
    "\n",
    "**Main takeaways:**\n",
    "\n",
    "- 3 of the images were of the same picture coming from Tumblr displaying the text \"the image you're requesting is no longer available\"\n",
    "- 1 is a drawing with an SFW picture but NSFW text\n",
    "- 4 of the images are mislabeled in the dataset\n",
    "- The remaining image is correctly labeled - it shows a couple having sex.\n",
    "\n",
    "To summarize, all but one of these images were misclassified because of **issues with the dataset**. Some of the images are in the **wrong category**, or are an artifact of **missing links** when downloading them from the internet. Drawings and images featuring heavy text content could potentially be excluded altohether, or limited to cartoons/hentai.\n",
    "\n",
    "This is good news because it means that we could potentially see the accuracy improve just by **cleaning and improving the overall quality of the dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvrGszw9Cr9J"
   },
   "outputs": [],
   "source": [
    "# Only for the brave! \n",
    "interp.plot_top_losses(9, nrows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67naWCAlRwuV"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This experiment shows that transfer learning with ResNet50 and a custom NSFW dataset is a promising baseline for further explorations, both in terms of accuracy and a reasonable training time.\n",
    "\n",
    "Some possible next steps would be **cleaning the dataset** to reduce noise and using **data augmentation** to reduce overfitting. \n",
    "\n",
    "Simply **adding more images** is another possibility, although I would have to test training times in TF-Keras too (quite a bit slower, in my experience) to see if that is feasible with my setup."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NSFW-resnet50-baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
