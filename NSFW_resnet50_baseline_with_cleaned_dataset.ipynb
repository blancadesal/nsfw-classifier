{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bu-UZ99rILw"
   },
   "source": [
    "# **NSFW Classifier - Improving the baseline**\n",
    "\n",
    "## **Purpose**\n",
    "\n",
    "In the previous notebook, we obtained a baseline for NSFW classification by fine tuning a pretrained ResNet50 model during 5 epochs on a custom dataset containing ~4900 images.\n",
    "\n",
    "The accuracy obtained in this way was ~92.5%. While the training loss decreased smoothly, the model showed early signs of overfitting. Displaying the \"worst\" misclassified images made it obvious that the dataset could greatly benefit from cleaning as it contained many mislabeled images, as well as pictures of text and other irrelevant image content.\n",
    "\n",
    "This notebook is the first of three experiments that aim to improve the model over the baseline in regards to accuracy and overfitting:\n",
    "\n",
    "1. **Experiment 1:** New baseline with a cleaned, extended dataset. Goal: improve accuracy.\n",
    "2. **Experiment 2:** New baseline with the old dataset + data augmentation. Goal: reduce overfitting.\n",
    "3. **Experiment 3:** New baseline with the cleaned, extended dataset + data augmentation. Goals: improve accuracy and reduce overfitting.\n",
    "\n",
    "Experiments 2 and 3 are published in separate notebooks. The methodology for all three experiments, as well as a summary of the results are detailed here.\n",
    "\n",
    "## **Methodology**\n",
    "\n",
    "### 1. Cleaning the dataset\n",
    "\n",
    "The dataset was cleaned by removing the following types of images:\n",
    "\n",
    "- Mislabeled images\n",
    "- Images with > 20% text overlays\n",
    "- Screenshots of Twitter, Instagram, Facebook, etc. posts\n",
    "- Memes\n",
    "- NSFW images pertaining to non-sexual, non-nude categories, e.g. gore, violence, bodily harm, etc. \n",
    "- Truncated images\n",
    "\n",
    "To make up for the deleted images and with the aim of reaching a dataset size of ~6000 total images, a further 1000 images of each category were downloaded and cleaned, thus obtaining a final dataset containing 3059 NSFW and 3110 SFW images (6169 total).\n",
    "\n",
    "### 2. Data augmentation\n",
    "\n",
    "Data augmentation was performed by resizing the images to 460 x 460 px, and then applying a series of of flip, rotate, zoom, warp, and lighting transforms using Fastai's utility function `aug_transforms()`:\n",
    "\n",
    "```\n",
    "aug_transforms(mult=1.0, do_flip=True, flip_vert=False, max_rotate=10.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=224, mode='bilinear', pad_mode='reflection', align_corners=True, batch=False, min_scale=0.75)\n",
    "```\n",
    "\n",
    "Note that the images are again resized during data transforms to end up being 224 x 224 px, the input format required by ResNet50.\n",
    "\n",
    "The reason for resizing the images to a relatively large size before applying any transforms is that this avoids problems such as ending up with empty patches in the corners following a rotation.\n",
    "\n",
    "The transforms are applied in batch, making them very fast when using a GPU runtime. \n",
    "\n",
    "## **Results**\n",
    "\n",
    "| Experiment | Accuracy | Overfitting | Observations\n",
    "| --- | --- | --- | ---\n",
    "| Baseline | 92.5% | Early | Many mislabeled images, overall noisy dataset\n",
    "| Cleaning | 95.3% | Early | There are still many mislabeled images in the dataset\n",
    "| Data Augmentation | 94.3% | Later | Dataset is as noisy as the one used for the baseline\n",
    "| Cleaning + Data Augmentation | 96.0% | Later| Some misclassified images represent more \"difficult\" examples - e.g. non-sexual partial nudity (bikini)\n",
    "\n",
    "## **Ideas for further improvement**\n",
    "\n",
    "### 1. Dataset improvement\n",
    "\n",
    "The dataset used so far is good enough for initial experimentation. However, having sifted through it image-by-image, I've become aware of some major flaws:\n",
    "\n",
    "- Male nudity, certain age groups, larger body sizes, and non-caucasian ethnicities are all underrepresented\n",
    "- Most images are user-generated content posted on reddit and tumblr \n",
    "- Sex scenes, as opposed to people posing alone, are underrepresented\n",
    "\n",
    "My first priority would therefore be to increase the diversity of image sources, as well as address the problem of underrepresented demographic groups. Additionally, I'd try to obtain the NPDI dataset commonly used for benchmarking in the scientific literature, as discussed in the Datasets report.\n",
    "\n",
    "In terms of dataset size, I would aim for 10-20k total images as that seems doable both in terms of training time on GPU, Google Drive storage space, and the time it takes to clean the data image-by-image.\n",
    "\n",
    "So far, I have been using a 80/20 train/validate split in all experiments. For the time being, I haven't needed an additional test set as the need to generalize to unseen data hasn't been addressed yet. This is however something that should be added. Ideally, the test set would be constructed by someone else than myself to avoid bias.\n",
    "\n",
    "### 2. Regularization\n",
    "\n",
    "While performance is good on the training data, with training loss converging smoothly and nearing the Bayes error toward the end of training, the validation loss stalls and diverges quite early on.\n",
    "\n",
    "Getting more data could help with overfitting. Realistically, there's a limit to the max size of the dataset I could use in practice due to space and training time constraints, and even at this max size, the model's representational capacity would still be too big in comparison, resulting in low bias (good) and high variance (bad), as evidenced by overfitting.\n",
    "\n",
    "The solution then could be to decrease model capacity by using techniques such as L2 and/or drop-out regularization, possibly with the addition of early stopping. \n",
    "\n",
    "### 3. Hyperparameter tuning\n",
    "\n",
    "So far, all experiments have been conducted using Adam as the optimizer, a constant learning rate of 0.003, and mini-batches of size 64.\n",
    "\n",
    "These, as well as other hyperparameters, can all be fine tuned. My approach here would be to use random search, rather than grid search, and use Fastai/PyTorch for prototyping to increase iteration speed. \n",
    "\n",
    "### 4. Model architecture\n",
    "\n",
    "If time allows, I would like to try out some methods I've come across in the scientific literature during the research phase of this project:\n",
    "\n",
    "- Substituting the last pooling layer with a Spatial Pyramid Pooling layer (SPP) to allow for variable input sizes, thus avoiding cropping/warping the images to fit ResNet50's required input size (224 x 224). \n",
    "- USE an SVM instead of Softmax as the output layer.\n",
    "- Adding an Attention module to the architecture.\n",
    "- Adding a pre-processing module to make the model robust against adversarial attacks.\n",
    "\n",
    "## **Conclusions**\n",
    "\n",
    "Transfer learning with ResNet50 shows promising preliminary results in developing an NSFW classifier. The next steps in development would be improving and extending the existing dataset, as well as adding regularization to reduce overfitting.\n",
    "\n",
    "The rest of this notebook, as well as the other notebooks containing the experiments mentioned here are \"bare-bones\" code, as all relevant methodology and results have already been discussed here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWIOUO864VMk"
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wso7bcImurkV"
   },
   "outputs": [],
   "source": [
    "# Setup Fastai Colab environment\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQae-K8Su8mh"
   },
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.all import *\n",
    "import os\n",
    "\n",
    "# Some files got mildly corruped during upload to Google Drive.\n",
    "# This helps avoids some problems down the line\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfJJvYOuDUSw"
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Fv1wt-12vtb3",
    "outputId": "69b2d6f4-0785-4224-db7e-4b27ebd3edba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NSFW', 'SFW']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify image folder location\n",
    "os.listdir(\"../content/gdrive/My Drive/Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "060BAvMav5Pe",
    "outputId": "51fe32c3-09d6-4599-b22b-0c1cd8a491a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('../content/gdrive/My Drive/Datasets/NSFW'),Path('../content/gdrive/My Drive/Datasets/SFW')]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Path object to image folders\n",
    "path=Path(\"../content/gdrive/My Drive/Datasets\")\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Wz364vZFh7EN",
    "outputId": "75d5b4e9-ac69-4a5c-9138-0e6691182283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total NSFW images: 3059\n",
      "total SFW images: 3110\n"
     ]
    }
   ],
   "source": [
    "print('total NSFW images:', len(os.listdir(os.path.join(path, \"NSFW\"))))\n",
    "print('total SFW images:', len(os.listdir(os.path.join(path, \"SFW\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6rj8krK_B2A"
   },
   "source": [
    "## Setting up the image dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z8Ch-rowWF8"
   },
   "outputs": [],
   "source": [
    "# Define input params for data block \n",
    "\n",
    "# This sets up a train/validate split of 80/20\n",
    "splitter=RandomSplitter(valid_pct=0.2, seed=seed) \n",
    "# ResNet50 requires an input size of (224, 224, 3)\n",
    "item_tfms = [Resize(224)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMcPXZCOw8Mk"
   },
   "outputs": [],
   "source": [
    "# Create blueprint for dataloader\n",
    "data_block = DataBlock(\n",
    "                  blocks=[ImageBlock, CategoryBlock],\n",
    "                  get_items=get_image_files,\n",
    "                  get_y=parent_label,\n",
    "                  splitter=splitter,\n",
    "                  item_tfms=item_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlOfIAYaw_jH"
   },
   "outputs": [],
   "source": [
    "# Create dataloader with batch size = 64 \n",
    "dls = data_block.dataloaders(path, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzGaPw9Txy-P"
   },
   "outputs": [],
   "source": [
    "# Run this cell at your own peril!\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Lafiwwa_S-t"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ercRgO61ySOs",
    "outputId": "ee8604c9-3a60-489b-96ac-e5704af8631a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "function ClickConnect(){\n",
       "console.log(\"Working\");\n",
       "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
       "}setInterval(ClickConnect,60000)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prevents getting disconnected, use only when training in Colab\n",
    "%%javascript\n",
    "function ClickConnect(){\n",
    "console.log(\"Working\");\n",
    "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
    "}setInterval(ClickConnect,60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "f65d381b5c9347a4bd35ff310bb68fb3",
      "4ada44a396d14bc6bbfa703309efe929",
      "d35d118070704b0e83978f0fb86a9906",
      "75ed4479af754d789dc759e349497cce",
      "249e7f559005486b93871fa18940a2c6",
      "8de8cdd0341d419682ff7f6eea65ebe4",
      "8479de12c63a4f0fbd05a06e2e761d1f",
      "0a1391ed5d2b4538be1c26f05dcf123b"
     ]
    },
    "id": "rGL6WlYyyv1S",
    "outputId": "93f241c6-2ba0-4718-890c-12d67f17e5c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65d381b5c9347a4bd35ff310bb68fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.373216</td>\n",
       "      <td>0.197624</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>17:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.213549</td>\n",
       "      <td>0.150637</td>\n",
       "      <td>0.947283</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.126702</td>\n",
       "      <td>0.191907</td>\n",
       "      <td>0.935118</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083098</td>\n",
       "      <td>0.174107</td>\n",
       "      <td>0.946472</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.043833</td>\n",
       "      <td>0.164838</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.022807</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.952960</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate a pre-trained model \n",
    "learn = cnn_learner(dls, resnet50, metrics=accuracy)\n",
    "# Train for 5 epochs\n",
    "learn.fine_tune(5, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "cw6lrfp0zhpZ",
    "outputId": "22ca6c24-0459-4f07-d0fa-f77d54bfb39c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvrGszw9Cr9J"
   },
   "outputs": [],
   "source": [
    "# Only for the brave! \n",
    "interp.plot_top_losses(9, nrows=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NSFW-resnet50-baseline-with-cleaned-dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a1391ed5d2b4538be1c26f05dcf123b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "249e7f559005486b93871fa18940a2c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4ada44a396d14bc6bbfa703309efe929": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75ed4479af754d789dc759e349497cce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a1391ed5d2b4538be1c26f05dcf123b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8479de12c63a4f0fbd05a06e2e761d1f",
      "value": " 97.8M/97.8M [27:36&lt;00:00, 61.9kB/s]"
     }
    },
    "8479de12c63a4f0fbd05a06e2e761d1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8de8cdd0341d419682ff7f6eea65ebe4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d35d118070704b0e83978f0fb86a9906": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8de8cdd0341d419682ff7f6eea65ebe4",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_249e7f559005486b93871fa18940a2c6",
      "value": 102502400
     }
    },
    "f65d381b5c9347a4bd35ff310bb68fb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d35d118070704b0e83978f0fb86a9906",
       "IPY_MODEL_75ed4479af754d789dc759e349497cce"
      ],
      "layout": "IPY_MODEL_4ada44a396d14bc6bbfa703309efe929"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
